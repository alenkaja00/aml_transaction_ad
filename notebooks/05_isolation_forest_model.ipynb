{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET = \"HI-Small\" ## either HI-Small or LI-Small\n",
    "\n",
    "DATASET_LOCATION = f\"../datasets/synthetic/03_feature_engineering/{DATASET}-features\"\n",
    "GFP_FEATURES_LOCATION = f\"./datasets/synthetic/03_feature_engineering/{DATASET}-enriched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(DATASET_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix a 2-hours difference (mismatch between pyspark and pandas) \n",
    "print(data['timestamp'].min(), data['timestamp'].max())\n",
    "data['timestamp'] = data['timestamp'] + pd.Timedelta(hours=2)\n",
    "print(data['timestamp'].min(), data['timestamp'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "data[\"timestamp\"] = data[\"timestamp\"].values.astype(int) // 10**9\n",
    "min_timestamp = data[\"timestamp\"].min()\n",
    "data[\"timestamp\"] = data[\"timestamp\"] - min_timestamp\n",
    "data = data.sort_values(by='timestamp', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "enriched_data = pd.read_parquet(GFP_FEATURES_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine dataset from feature engineering and dataset from graph feature preprocessor\n",
    "data = data.merge(enriched_data, on='transaction_id', how='left')\n",
    "data = data.sort_values(by=\"timestamp\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = data.drop(columns=['target', 'source', 'target_bank', 'source_bank', 'transaction_id',\n",
    "'timestamp', 'source_currency', 'target_currency', 'source_amount', 'target_amount', 'format',\n",
    "'is_laundering', 'amount'])\n",
    "X_train_columns = X_train.columns\n",
    "\n",
    "y_target = data[['transaction_id', 'is_laundering']].copy()\n",
    "y_target_columns = y_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill null and inf values and change type\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_train = X_train.replace([np.inf, -np.inf], 0)\n",
    "X_train = X_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use a subset of features mainly focused on amount, velocity, counterparties,\n",
    "# and patterns like cycles, fan-in and fan-out\n",
    "selected_features = ['percentage_of_total_sent', 'percentage_of_total_received',\n",
    "        'percentage_of_total_last_5_d_sent', 'percentage_of_total_next_5_d_sent',\n",
    "        'percentage_of_total_last_5_d_received', 'percentage_of_total_next_5_d_received',\n",
    "        'is_round_amount', 'daily_trans_count_counterparty', 'total_interactions',\n",
    "        'weekly_interactions', 'dst_daily_percentage_of_counterparty',\n",
    "        'percentage_weekly_sent', 'percentage_weekly_received',\n",
    "        'percentage_daily_sent', 'src_percentage_of_interactions',\n",
    "        'dst_percentage_of_interactions', 'src_time_diff', 'dst_time_diff',\n",
    "        'fan_in_bins_4-5', 'fan_in_bins_5-6', 'fan_in_bins_6-7',\n",
    "        'fan_in_bins_7-8', 'fan_in_bins_8-9', 'fan_in_bins_9-10',\n",
    "        'fan_in_bins_11-12', 'degree_out_bins_6-7', 'degree_out_bins_8-9',\n",
    "        'temp-cycle_bins_2-3', 'temp-cycle_bins_3-4', 'temp-cycle_bins_4-5',\n",
    "        'lc-cycle_bins_2-3', 'source_ratio_out', 'source_min_col3_out', \n",
    "        'source_kurtosis_col3_out', 'source_sum_col4_out', 'source_fan_in',\n",
    "        'source_ratio_in', 'source_min_col3_in', 'dest_ratio_in', 'dest_min_col3_in']\n",
    "X_training = X_train[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate outlier fraction (since the target is available)\n",
    "outlier_fraction = len(data[data['is_laundering'] == 1]) / len(data)\n",
    "print(outlier_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "trees = 100\n",
    "samples = 0.1\n",
    "jobs = -1\n",
    "state = 42\n",
    "\n",
    "model = IsolationForest(n_estimators=trees,\n",
    "                        max_samples=samples, \n",
    "                        contamination=outlier_fraction,\n",
    "                        n_jobs=jobs,\n",
    "                        random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the IF model\n",
    "model.fit(X_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference and export predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the trained IF model to compute anomaly scores for the training data\n",
    "scores = model.decision_function(X_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Invert and scale Isolation Forest scores to [0, 1], where higher scores indicate anomalies\n",
    "inverted_scores = -scores\n",
    "inverted_scores = (inverted_scores - inverted_scores.min()) / (inverted_scores.max() - inverted_scores.min())\n",
    "scaled_scores = inverted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation = pd.concat([X_training, y_target], axis=1)\n",
    "evaluation[\"scores\"] = scaled_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the 70% percentile as threshold to separate between normal and abnomal transactions\n",
    "THRESHOLD = 0.7\n",
    "threshold = evaluation['scores'].quantile(THRESHOLD)\n",
    "\n",
    "predictions = [1 if score>=threshold else 0 for score in evaluation['scores']]\n",
    "evaluation['predictions'] = predictions\n",
    "\n",
    "TP = evaluation[(evaluation['predictions'] == 1) & (evaluation['is_laundering'] > 0)].shape[0]\n",
    "FN = evaluation[(evaluation['predictions'] == 0) & (evaluation['is_laundering'] > 0)].shape[0]\n",
    "FP = evaluation[(evaluation['predictions'] == 1) & (evaluation['is_laundering'] <= 0)].shape[0]\n",
    "TN = evaluation[(evaluation['predictions'] == 0) & (evaluation['is_laundering'] <= 0)].shape[0]\n",
    "\n",
    "print(f\"True Positives: {TP}\")\n",
    "print(f\"False Negatives: {FN}\")\n",
    "print(f\"False Positives: {FP}\")\n",
    "print(f\"True Negatives: {TN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the result metrics for the model\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "specificity = TN / (TN + FP)\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "tpr = TP / (TP + FN)\n",
    "tnr = TN / (TN + FP)\n",
    "fpr = FP / (FP + TN)\n",
    "fnr = FN / (FN + TP)\n",
    "average_precision = average_precision_score(evaluation['is_laundering'], evaluation['scores'])\n",
    "auc = roc_auc_score(evaluation['is_laundering'], evaluation['scores'])\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1-Score: {f1:.2%}\")\n",
    "print(f\"Specificity: {specificity:.2%}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"False Positive Rate (FPR): {fpr:.2%}\")\n",
    "print(f\"False Negative Rate (FNR): {fnr:.2%}\")\n",
    "print(f\"Average Precision (AP): {average_precision:.2%}\")\n",
    "print(f\"True Positive Rate (TPR): {tpr:.2%}\")\n",
    "print(f\"True Negative Rate (TNR): {tnr:.2%}\")\n",
    "print(f\"AUC: {auc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation.sort_values(by='scores', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "percentage = outlier_fraction * 100\n",
    "cutoff_index = int(len(evaluation) * (percentage / 100)) \n",
    "cutoff_score = evaluation['scores'].nlargest(cutoff_index).min()\n",
    "\n",
    "evaluation['predicted_anomaly'] = (evaluation['scores'] >= cutoff_score).astype(int)\n",
    "\n",
    "f1 = f1_score(evaluation['is_laundering'], evaluation['predicted_anomaly'])\n",
    "print(f\"F1-Score: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_trans = evaluation[evaluation['is_laundering'] == 0]\n",
    "normal_trans_sample = evaluation[evaluation['is_laundering'] == 0].sample(frac=0.2, random_state=42)\n",
    "laundering_trans = evaluation[evaluation['is_laundering'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the IF scores distribution for identified normal and abnormal transactions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(normal_trans_sample.index, normal_trans_sample['scores'], c='#007191', s=20, label='Normal Transactions', alpha=0.7)\n",
    "plt.scatter(laundering_trans.index, laundering_trans['scores'], c='#f47a00', s=20, label='Laundering Transactions', alpha=0.7)\n",
    "plt.xlabel('Transactions', fontsize=12)\n",
    "plt.ylabel('Anomaly Score', fontsize=12)\n",
    "plt.legend(frameon=True, shadow=True, fontsize=10)\n",
    "plt.grid(False)\n",
    "plt.title(f\"{DATASET}: IF scores distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the IF scores distribution for identified normal and abnormal transactions\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.hist(normal_trans['scores'], bins=200, alpha=0.7, label='Normal Transactions', color='#007191')\n",
    "ax1.set_xlabel('Anomaly Score', fontsize=12)\n",
    "ax1.set_ylabel('Frequency (Normal Transactions)', color='#007191', fontsize=12)\n",
    "ax1.tick_params(axis='y', labelcolor='#007191')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.hist(laundering_trans['scores'], bins=200, alpha=0.7, label='Laundering Transactions', color='#f47a00')\n",
    "ax2.set_ylabel('Frequency (Laundering Transactions)', color='#f47a00', fontsize=12)\n",
    "ax2.tick_params(axis='y', labelcolor='#f47a00')\n",
    "ax2.set_ylim(0, 70)\n",
    "ax1.grid(False)\n",
    "ax2.grid(False)\n",
    "fig.tight_layout()\n",
    "fig.legend(frameon=True, shadow=True, fontsize=10)\n",
    "plt.title(f\"{DATASET}: IF scores distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine two visualizations in the same plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.scatter(normal_trans_sample.index, normal_trans_sample['scores'], c='#007191', s=20, label='Normal Transactions', alpha=0.7)\n",
    "ax1.scatter(laundering_trans.index, laundering_trans['scores'], c='#f47a00', s=20, label='Laundering Transactions', alpha=0.7)\n",
    "ax1.set_xlabel('Transactions', fontsize=12)\n",
    "ax1.set_ylabel('Anomaly Score', fontsize=12)\n",
    "ax1.legend(frameon=True, loc='upper left', fontsize=10, shadow=True)\n",
    "ax1.grid(False)\n",
    "\n",
    "ax3 = ax2.twinx()\n",
    "ax2.hist(normal_trans['scores'], bins=200, alpha=0.7, label='Normal Transactions', color='#007191')\n",
    "ax2.set_xlabel('Anomaly Score', fontsize=12)\n",
    "ax2.set_ylabel('Frequency (Normal Transactions)', color='#007191', fontsize=12)\n",
    "ax2.tick_params(axis='y', labelcolor='#007191')\n",
    "\n",
    "ax3.hist(laundering_trans['scores'], bins=200, alpha=0.7, label='Laundering Transactions', color='#f47a00')\n",
    "ax3.set_ylabel('Frequency (Laundering Transactions)', color='#f47a00', fontsize=12)\n",
    "ax3.tick_params(axis='y', labelcolor='#f47a00')\n",
    "ax3.set_ylim(0, 600)\n",
    "ax2.legend(frameon=True, loc='upper right', fontsize=10, shadow=True,)\n",
    "ax3.legend(frameon=True, loc='upper right',bbox_to_anchor=(1, 0.95), fontsize=10, shadow=True)\n",
    "ax2.grid(False)\n",
    "ax3.grid(False)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the AUC-ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(evaluation['is_laundering'], evaluation['scores'])\n",
    "roc_auc = roc_auc_score(evaluation['is_laundering'], evaluation['scores'])\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=150)\n",
    "plt.plot(fpr, tpr, color='#1f77b4', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray', label='Chance Level')\n",
    "plt.fill_between(fpr, tpr, alpha=0.2, color='#1f77b4')\n",
    "plt.title(f\"{DATASET}: AUC-ROC Curve\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FP Rate)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (TP Rate)', fontsize=12)\n",
    "plt.legend(loc=\"lower right\", frameon=True, shadow=True, fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export the IF model scores for the GNN-based model\n",
    "to_save = evaluation[['transaction_id', 'is_laundering', 'scores']]\n",
    "to_save.to_csv(f\"../datasets/synthetic/04_if_output/{DATASET}_if_scores.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu113.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
